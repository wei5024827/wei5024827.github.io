## Hadoop之ZooKeeper

#### Zookeeper的节点类型

1. 永久无序节点

2. 临时无序节点

3. 永久序列节点

4. 临时序列节点


#### Zookeeper集群角色

1. Leader：处理事务性操作

2. Follower：处理非事务性操作，参与Leader选举投票

3. Observer：处理非事务性操作，不参与Leader选举投票


#### Zookeeper应用场景

1. 数据发布和订阅
2. 提供集群的选举
3. 分布式锁

#### Zookeeper的容错机制？

- 每个ZK存储的内容都是一致的
- 每个ZK都能接受客户端请求
- 每个ZK有权利参加选举成为Leader

#### Zookeeper的选举机制？

- 先按照zxid进行选举：谁的zxid越大，谁的优先权越高

  - zxid：数据id

- 如果zxid相同，按照myid进行选举，超过半数，选举成立

  - myid：权重id



## Hadoop之HDFS

#### HDFS三副本策略

为了防止服务器宕机导致数据丢失，HDFS采用了三副本机制

第一个副本：存储在本地

第二个副本：存储在不同于第一个副本的机架

第三个副本：存储在和第二个副本同一个机架，不同的机器。

#### HDFS写流程

- step1：客户端提交一个写入请求NN，NN检查权限等是否合法的信息，如果不合法，直接返回错误
- step2：客户端将文件进行分块，提交第一个块的写入请求给NameNode，NameNode会根据分配策略返回这个块的三个副本的存储节点的位置
- step3：客户端提交这个块的写入请求给离自己最近的节点，构建Pipelinee管道，客户端和三个节点依次构建管道，开始传输Package
- step4：每个Package传输完成以后，逐级返回ack，直到整个块传输完毕
- step5：客户端请求提交下一个块的写入

#### HDFS读流程

- step1：客户端提交读的请求给NameNode，NameNode检查合法性，如果合法检索元数据，返回这个文件的每个块对应的地址
- step2：客户端从离自己最近的节点上获取每个块，将所有块合并

####  HDFS组成架构

1. NameNode：管理名称空间，管理块的映射信息，处理客户端读写请求

2. DataNode：存储数据块，执行读写操作

3. SecondaryNameNode：分担NN工作量，定期合并镜像文件和日志，当NN挂掉，辅助恢复NN


#### HDFS小文件弊端，如何优化？

- 弊端：小文件会产生大量的索引，拖累NameNode
- 解决方案：利用archive进行小文件合并

#### HDFS HA架构中有哪些进程？

- NameNode：Active、Standby
- DataNode
- ZKFC：负责监听NameNode，辅助NameNode进行选举，到ZK中进行注册
- JournalNode：负责存储元数据日志文件edits文件，用于实现保证Active和StandBy的元数据一致性

## Hadoop之MapReduce

#### MR执行流程 

- map阶段

  - mapper从hdfs读数据，将数据切块，默认切块大小为hdfs的块大小，利用map函数将块中的数据解析成kv。

- shuffle

  - 对kv进行Hash分区，分区后加载到缓冲区，当缓冲区存储到达80%后，锁定这部分数据，在内存中进行快速排序，再溢出到磁盘，形成有序的小文件。
  - 将磁盘中的小文件合并为整体有序的大文件。
  - reduce拉取属于自己分区的数据，将属于自己的每个maptask的数据进行合并并排序

- reduce阶段

  最终按照key值分组排序，将结果写入HDFS文件系统中
  
  

#### MapReduce优化方法

1. 数据输入时合并小文件
2. map阶段
   - 调整内存和溢出比例上限，减少spill次数
   - 增大merge文件数目，减少merge次数
3. reduce阶段
   - 设置map，reduce并行
   - 尽量规避reduce



## Hadoop之YARN和HA

#### YARN执行流程

用户向yarn提交请求程序，ResourceManager给程序分配一个containar，并与NodeManager通信要求他在containaer中启动APPmaster，

APPmaster向RM注册，向RM汇报程序运行状态，并请求资源、请求到资源后，APPmaster在NodeManager中启动任务，启动后由APPmaster监测任务运行状态，应用运行结束后，APPmaster注销并关闭



#### YARN三大组件

1. ResourceManager 负责整个集群的资源管理和分配

2. NodeManager 负责每台机器上的资源管理

3. ApplicationMaster 负责监督程序内部资源的申请和运行情况

   

#### YARN三大调度策略

1. 先进先出策略

2. 容量调度策略

3. 公平调度策略

   

#### HA是什么，作用是什么？

HA是高可用模式，主要解决单点故障问题



## Hive

####  Hive建表的方式

```shell
create table t_archer(
      字段名称 字段类型 comment "字段注释",
) comment "表注释"
partitioned by (分区字段 类型)	#创建分区表，分区字段不能与表中的字段一样
CLUSTERED BY(分桶字段) INTO 分桶个数 BUCKETS; #创建分桶表，分桶的字段一定要是表中已经存在的字段
location '/aaa'					#使用location关键字指定本张表数据在hdfs上的存储路径
row format delimited   		#SerDe序列化机制，Hive使用SerDe机制读写HDFS上文件，如果没有这段语法，默认使用"\001"
fields terminated by "\t";  #指定字符之间的分隔符
map keys terminated by ","; #指定map类型kv之间分隔符
lines terminated by "\n";   #指定换行符
```

#### Hive数据加载

普通表：直接将文件放在表的目录下，直接可以识别

分区表：

- 静态分区加载

  ```sql
  load data local inpath '/a.txt' into table tb_name partition(分区字段='分区值');
  ```

- 动态分区加载

  ```sql
  #动态分区模式分为strict严格模式  nonstrict非严格模式
  #严格模式要求 分区字段中至少有一个分区是静态分区。
  insert into table tb_name partition(role_dong) 
  select tmp.*,tmp.role_main from tb_name;
  
  #动态分区相当于在表的最后增加一列，所以在查询语句后将分区的表的原有字段与之对应	
  ```

分桶表：

```sql
insert into tb_name select * from 已存在的表
```

#### 分区表，分桶表的区别以及各自的优点？

- 分区表本质是将分区创建为多个文件夹，使用分区表查询字段可以减少全表扫描，提高查询效率；
- 分桶表的本质是按照字段将文件拆分为多个文件，分桶表在Join时可以减少笛卡尔积的数量，提高join效率。

#### Hvie内部表和外部表的区别？

外部表用external声明，外部表在删除的时候，只删除元数据，HDFS上的数据文件不会动

内部表元数据和数据都会被删除。

#### Hive优化方式有哪些？

- 属性优化：
  - fetch抓取机制：能不走mr尽量不走mr
  - 本地模式
  - 开启推测执行机制：通过算法找到拖后腿的task，创建备份task一起跑，谁先处理完用谁作为最终结果
  - map join
  - 分桶join
  - 小文件处理

- SQL优化

  过滤，处理

  where  having

  大表过滤为小表

- 设计优化？
  - 分区表
  - 分桶表
  - 文件存储：列式存储，ORC索引

#### Hive常见的数据压缩方式有哪些？

snappy，bzip2，gzip，lzo

常用的是snappy，mapreduce中会使用，hadoop本身不支持，需要安装。

hadoop自带的gzip不需要安装



#### Hive两张表关联，使用MapReduce如何实现

- 小表join，直接使用map join，不经过reduce端

- 如果两张都是大表，采用联合key，即join on中的公共字段，在map阶段 按照key进行分区，reduce阶段聚合

  

#### Hive保存元数据的方式

内嵌式，本地，远程



#### Hive行列装换

- 多行转单列
  - collect_set：去重
  - collect_list：不去重

- 多列转单行

  - explode+ lateral view

    

#### HiveQL语句如何在Shell运行？

hive -e xxxx.sql



#### 增量处理，如何让SQL语句中日期动态变化

hive命令中使用hiveconf定义日期变量，并在SQL文件中引用

#### UDF,UDAF,UDTF

- udf：操作单个数据行，产生单个数据
- udaf：操作多个数据行，产生单个数据行：sum，avg
- udtf：操作一个数据行，产生多个数据行作为一个表输出，比如json字符串数据变成一个表



## 数据仓库

#### 数仓是干甚的？

数据存储与加工处理



#### 数仓的特性

- 面向主题

- 数据集成

- 非易失

- 时变性



#### 什么是分层？分层的本质是什么？

本质是规范化数据的处理过程

每一层在Hive就是一个数据库



#### 为什么要分层？

- 清晰数据结构

- 数据血缘追踪

- 减少重复开发

- 把复杂问题简单化

- 屏蔽原始数据异常对业务的影响



#### 如何分层？

- ODS：原始数据

- DW：数据仓库层
  - DWD 实现ETL
  - DWM 轻度聚合
  - DWS 最终聚合

- 数据应用层



#### 什么是建模？

本质：决定数据存储方式，表的设计



#### 为什么建模？

大数据系统有性能问题，成本问题，效率问题，质量问题，建模来解决平衡这些问题



#### 有哪些建模方法

ER模型

维度模型



#### 如何构建维度模型

- 选择业务过程

- 声明粒度

- 确认维度

- 确认度量的事实

  

#### 具体的实施流程

1. 需求调研
2. 划分主题域
3. 构建维度总线矩阵
4. 明确指标统计
5. 定义事实与维度规范
6. 代码的开发



## 在线教育项目

#### 项目中遇到过什么问题？（Hive问题）

- 内存溢出

  - 堆内存不足：给task分配更多的内存
  - 物理内存不足
    - 允许NodeManager使用更多的内存
    - 调整代码，避免Map Join
  - 虚拟内存不足

- Hive中的数据倾斜：ReduceTask数据分配不均匀

  - 原因与解决

    - group by

      1. 开启Combiner

      2. 随机分区

         方式一：开启skewindata

         方式二：手动指定 distribute by rand()

    - join

      1. 避免走Reduce Join
      2. 开启skewjoin






## 项目简述：

项目是基于Hive所研发的ETL大数据教育平台

那为什么要开发这个项目呢，在这几年随着公司规模的提升，业务量已经很大了，有些周期会存在业务负增长的情况

面对这种情况，急需从数据分析的角度来找到负增长的原因，也希望通过数据分析的方式优化当前的业务，公司前期业务数据通过Mysql进行存储，这种技术不满足分析和存储的需求，所以公司决定通过建立数仓的方式，来解决这一问题。

我们开发的大数据平台主要解决两个方面的需求。

一是分析出一个客户从访问到报名每个环节的留存率和流失率，发现并优化其中存在的问题，然后提高报名率。

第二是通过数据分析仓库这个技术，来对学员的考勤，考试等学习状况做管理和把控，以此来提升自己的品牌口碑。

通过需求分析，我们划分了三个领域主题，分别是访问和咨询分析主题，线索，意向和报名分析主题以及学员考勤主题

那么如何实现这些主题的分析。

访问分析主题和咨询分析主题数据来源主要是客服系统数据库，来源表有两张，分别是网站访问表与客服咨询表。在这个主题下，用这两表我们构建了OBS层，在DW层构建了DWD层和DWS层来实现最终不同维度下的访问分析和咨询分析表。

线索，意向，报名分析主题来源主要是营销系统数据库，用到的表有八张，在DW层构建了六层，最终实现了不同维度下意向分析的结果和报名分析的结果。

考勤分析主题数据来源主要是学员管理系统，用到的表有五张，在DW层构建了DIM，DWM和DWS层，最终实现了班级的考勤分析报表。

我们利用Hadoop的采集工具Sqoop，将这些原始数据进行字段的过滤，然后采集到Hive当中，在APP层的数据导出过程中，也使用了Sqoop这个工具。

在开发过程中，我使用Hue来进行HDFS，HiveQL的可视化操作。使用Oozie进行任务流调度，完成每日的自动化数据分析。开发过程中使用Git来完成版本控制。

并在最后我们利用了FineBI做了一个可视化的报告页面，方便管理层更直观的观察最终的数据结果。









 	
