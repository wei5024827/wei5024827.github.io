### RDD及算子

#### RDD概念及其特性

RDD是弹性分布式数据集

RDD五个特性：

1. RDD包含多个分区
2. 处理数据时，每个分区用函数进行处理
3. RDD中有依赖关系
4. RDD数据类型为KV，可以设置分区器
5. 对RDD分区数据进行计算时，找到最佳位置列表

#### RDD函数分类，并举例

- 转换函数：返回值为RDD
  - map，filter，flatMap，union，distinct
- 触发函数：返回值非RDD
  - count，foreach，collect，reduce，saveAsTextFile

#### RDD如何持久化，其作用是什么？

- 调用cache()和persist()实现持久化
  - cache：持久化到内存中
  - persist：持久化到磁盘中

- 作用：某些RDD计算或转化需要耗费一定的时间，而且后续还会继续用到，就可以将RDD持久化

#### RDD的Checkpoint作用

RDD持久化将数据缓存在内存中，可靠性比较差，存在磁盘也会损坏。Checkpoint可以将持久化的数据存放在高容错，高可靠的分布式存储系统上，比如HDFS。

#### CheckPoint和持久化的区别

- 持久化的RDD的依赖关系是不变的。CheackPoint之后RDD的依赖关系就不存在了
- 持久化的数据丢失的可能性比较大，因为节点故障会导致内存断电丢失数据，但Check的数据存储在分布式系统中，安全性比较高

#### RDD广播变量和累加器，有什么应用场景

- 广播变量：将变量在所有节点的内存之间共享，每个机器上缓存一个只读变量。
  - 应用场景：
    - stage阶段的taskset在交付excutor处理时，会广播到其他节点
    - 当小文件进行join时，可以将小文件进行广播
- 累加器：不同节点之间的数据可以进行累加求和
  - 原理，将每个节点中Accumulator进行累加操作，然后Drive获取这个值，将其累加

#### RDD创建的方式有哪些？

- 使用程序中的集合创建RDD
- 使用本地文件系统创建RDD
- 使用HDFS创建RDD
- 使用数据库DB创建RDD
- 基于数据流，创建RDD

### SparkSQL

#### DataFrame是什么

带有Schema（元信息）的RDD

#### RDD转换DataFrame的方式

1. 自动推断
2. 自定义Schema
3. toDF函数

#### SparkSQL中数据的处理方式

1. DSL编程
2. SQL编程：将DataFrame注册为临时视图，编写SQL

#### Spark解析SQL的原理

用catalyst解释器



### Spark原理

#### Spark有哪几种部署模式，每种模式的特点？

- standalone模式：Spark自带资源管理，任务监控。
- spark on yarn模式：由yarn管理集群资源，任务调度。
- spark on mesos
- K8s

#### Spark为什么比MapReduce快？

- MR慢原因
  - MapReduce最多只有2个阶段，只有Map和Reduce阶段，每个阶段的结果必须写入磁盘
  - MapTask和ReduceTask是进程级别，每次进程的申请和销毁浪费大量的时间
  - Shuffle是固定流程：Spill、Merge、Merge、分组
- Spark快
  - 支持DAG，一个Spark程序中可以有任意多的阶段，对于不需要经过shuffle的过程，数据直接在内存中传递
  - 只申请一次运行进程Executor，所有Task都以线程级别来运行在进程中
  - Shuffle的功能由算子决定

#### Spark的数据本地性有哪几种？

- 本地性：Task运行的最佳位置
- Task运行在Executor中，一个程序可能会有多个Executor
  - PROCESS_LOCAL：放在数据所在Executor中运行
  - NODE_LOCAL：放在数据所在的Executor的同一台机器中的某个Executor中
  - RACK_LOCAL：放在同一个机架中的不同机器的Executor中运行



#### Spark程序由哪几部分组成

- Application：程序
- 进程：Driver，Executor
- 运行：Job，Stage，Task

#### DAG图是如何生成的

SparkContext利用回溯算法，将每个算子放入Stage中，如果遇到宽依赖，就构建一个新的Stage，最终形成DAG图

#### 宽依赖是怎么形成的？

父RDD中一个分区的数据到了子RDD中的多个分区，遇到shuffle，形成宽依赖



#### SPARK ON YARN流程

客户端把spark程序提交到ResourceManager，并启动Drive进程，然后Drive进程向ResourceManager申请Executor，ResourceManager根据提交的配置请求，启动Executor，启动之后所有Executor都与Drive反向注册，等待分配task；

Drive根据代码进行解析，遇到触发算子，触发Job运行，并调用DAGScheduler为当前Job使用回溯算法构建DAG图，遇到宽依赖算子就划分stage，每个stage转换为一个taskSet，taskSet中的每个task分配给Executor去运行。Drive会监控每个task的运行然后返回结果。



#### Spark程序的执行步骤

Step1：程序提交到Master，启动Driver进程，Driver向主节点申请启动资源进程Excutors，Master根据提交的配置请求在从节点worker中启动Executor，计算进程启动成功，所有的Executor向Driver反向注册，等待分配Task

Step2：进入解析阶段，Driver会根据代码进行逐行解析，遇到Action算子，触发执行Job

Step3：调用DAGScheduler为当前的job使用回溯算法构建DAG图

Step4：构建过程中每遇到一个宽依赖算子，就划分Stage

Step5：从Stage编号最小的开始，把每个Stage转换为一个TaskSet集合

Step5：将TaskSet的每个Task分配给Executor去运行

Step6：运行完成后，释放所有资源。

#### Spark中Driver的功能？

- 创建SparkContext实例
- 向集群申请资源
- 解析作业，生成Stage
- 调度Task到Executor

#### 为什么要用Spark on YARN？

- 资源统一化管理
- YARN资源管理机制要比Standalone资源管理机制更加灵活

#### Spark on YARN的不同deploymode的区别？

- deploymode：决定了Driver进程运行位置
  - client：默认模式，Driver运行在客户端节点
    - 问题：如果所有程序全部使用client模式
      - 这台客户端的负载过高
      - 这台机器一旦故障，所有程序都会受到影响
  - cluster：集群模式，Driver运行在某一台从节点上【工作中】

- Spark on YARN client
  - Driver和ApplicationMaster共存
  - Driver：解析、分配、监控Task
  - ApplicationMaster：向ResourceManager【ApplicationManager +  ResourceScheduler】申请资源
  - Executor：计算进程，运行所有Task
- Spark on YARN cluster
  - Driver运行在ApplicationMaster内部：合并
  - Executor：计算进程，运行所有Task

#### Spark Shuffle的过程

一个spark程序在执行过程中遇到宽依赖算子会执行shuffle

shuffle的本质是将不同分区的RDD按照Key值进行重新分区。

shuffle有两个阶段，第一个阶段shuffle write，第二个阶段shuffle read

在执行shuffle write时，首先程序会判断会不会执行bypass运行机制，如果程序的map task的个数是否小于BypassMerge的值，如果小于的话，就会执行bypass机制，也就是执行hash shuffle

如果大于的话，默认执行sort shuffle

以sort shuffle为例，不同分区的RDD会先在内存中进行一次排序，然后进入缓冲区，当在缓冲区达到阈值时，会溢写到磁盘，形成一个小文件，当这个分区的数据都溢写完成后，所有的小文件合并成一个大文件，同时生成一个索引文件，供shuffle read快速查询Key对应的数据使用。

进入shuffle read阶段后，根据不同的算子，执行不同的功能。比如groupbykey：做分组  sortbykey：做排序。repatition：做分区。

这就是一个完整的shuffle过程。



### Spark优化

#### Spark的调优

- 对多次使用的RDD进行持久化操作cache，persist，checkpoint，这样第二次使用RDD数据的时候就不用再进行重新计算

- 使用parallelize等方法设置提高并行度，增加CPU处理的核数，来提高程序的运行效率

- 广播共享数据，对于数据量不大的文件，要执行join操作时，可以广播到各个节点，减少网络资源消耗

- 数据本地化，调整spark等待task可以进行本地化的时间，来提升数据本地化的级别
- 对shuffle的一些配置进行设置，达到调优的效果
  - 调整map task缓冲区的大小，shuffle过程中会有一个数据进入缓冲区，溢写磁盘的过程。适当的把缓冲区调大，可以减少溢出小文件的数量
  - 调整reduceTask的拉取缓存，调大点可以加快reduce阶段的执行速度
  - 拉取失败最大重试次数，有些时候网络不稳定会导致数据拉取失败，可以多次重试
  - 调整shuffle的内存占用，如果程序较多使用了shuffle操作，可以适当调大
  - shufflemanager，默认是sort，如果不需要业务逻辑中不需要排序，可以改为hash
  - 使用hash shuffle，会产生大量的小文件，可以开启consolidateFiles，可以将小文件大幅度合并。



#### Sprak数据倾斜怎么解决？

在shuffle中，遇到join或者按key聚合的操作，把大量相同的key拉取到一个task处理，这时就发生了数据倾斜

- 过滤少数几个导致数据倾斜的key，使用场景比较少，大多数情况下导致倾斜的key还是很多的
- 提高shuffle read的并行度，增加shuffle read task的数量，可以重新把不同的key分配到不同的分区。可以有效环节的数据倾斜
- 如果碰到聚合类算子，可以用两阶段聚合，局部聚合再全局聚合的方式解决数据倾斜
- 将reduce join转为map join，可以将数据量较小的RDD通过广播的方式发送到每个节点，然后再join，这样就避免了shuffle过程，完全避免了数据倾斜的发生。

#### Hive One Spark： bug

datediff over 子查询 =》 null point

解决方案：

1、换MR引擎

2、将时间字段由string换为date类型
