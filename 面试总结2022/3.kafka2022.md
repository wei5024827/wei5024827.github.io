#### kafka应用场景

- 消息队列，大数据实时架构中比用kafka
- 流式计算

#### 什么是Broker、Producer、Consumer、Topic、Partition、Segment、Offset？

- Broker，kafka是主从架构的分布式框架，主节点是Controller，从节点是Broker
- Producer，Kafka的生产者，往kafka中生产数据
- Consumer，kafka的消费者，kafka往消费者中发送数据
- Topic，类似于表的概念，生产者将数据生产到kafka中时，会把数据写入在Topic中
- Partition，每个Topic都是按照分区存储的
- Segment，每个分区的数据都分成很多Segment小文件对，一个存放数据索引，一个存放真实数据
- Offset，segment的文件名，也是记录消费者消费数据的位置

#### kafka怎么保证数据安全的？

kafka用副本机制来保证数据安全，每个分区都对应多个副本，当一个分区的数据没了，用另一个分区的ISR副本数据来顶替。顶替的时候由LEO来确定

#### 分区副本分为哪些？

- ISR：可用副本

- OSR：不可用副本，因为网络延迟或者机器原因导致副本很久没有同步，成为了不可用副本

- AR：ISR+OSR：所有副本

#### LEO和HW是什么？作用是什么？

- LEO：确定选举哪个副本
  - 当前分区副本数据同步到的offset的位置+1，一般当leader副本丢失，就用LEO值最大的follower副本选举成为主副本

- HW：确定消费者能消费到的最大位置
  - 当前分区的leader副本以及follower副本同步的offset最小的值，一般消费者只能消费到offset最小值得那个分区数据


#### 生产者生产数据的规则是什么？Kafka生产者怎么实现生产数据的负载均衡？

- 首先看生产者有没有指定分区，指定了分区，按照分区生产数据
- 没有指定分区，看数据的key是否为Null，如果是Null，默认情况下回使用黏性分区（最新版本）或者轮询分区
- 如果Key的值不为Null，按照MUR取余的算法指定数据的分区
- 当然也可以自定义分区器，重写partition方法

#### 生产者生产数据的时候如何保证写入Kafka的数据不丢失不重复？Kafka保证生产的一致性语义？

生产者发送数据时等待kafka返回ack，来确保数据不丢失

ack有三种响应模式

0：不需要ack回应

1：发送一条数据，这条数据只要在kafka中有了一条副本，就返回ack

all：发送一条数据，这条数据在kafka中所有副本都同步好了，才返回ack

ack并不能保证数据不重复，比如kafka在返回ack的过程中ack因为网络故障丢掉了，生产者就认为kafka没有收到数据，会再把这份数据重新传一份给kafka，造成了数据重复。

这时需要使用幂等性机制，在生产者给kafka生产数据时每条数据都加上编号，kafka每次接收数据时会检查这条数据的id是否重复

#### 消费者消费数据的规则？消费者是怎么消费数据的？Kafka保证消费一次性语义？

消费者消费数据由三种方式

- 按照topic消费，在代码中指定subscribe Topic名称即可
- 按照分区消费，在代码中写明topic的分区数即可
- 按照offset消费，
  - 第一次消费的时候，根据属性来决定消费的位置
    - latest：默认，从Topic每个分区的最新位置开始消费
    - earliest：从offset为0的位置开始消费
    - none
  - 之后消费，按照上一次消费offset的位置继续消费，记录offset消费位置的数据会被同一统计进一个特殊topic：__consumer_offsets
  - 工作中：自己用消费者来管理offset，自己在代码中将offset存储在外部系统：MySQL、ZK、Redis

#### 消费分配策略有哪些？各自的应用场景？消费者消费如何保证消费各区的数据均衡。

- 范围分配：把分区数据均分给消费者，不能均分的，把余数分配给消费id小的，一般不用
- 轮询分配：按照topic的名称和分区编号排序，轮询分配给消费者，适合多个消费者订阅了共同的topic，适用于大多数场景
- 黏性分配：消费者如果订阅了不同的Topic，轮询分配失效，就按照黏性算法进行分配

#### Kafka的写入过程

- 生产者将数据写入batch中，batch达到阈值，提交写入请求
- 生产者根据分区规则构建分区，将写请求提交给leader副本所在的各个节点中
- 写入这台节点的PageCache中
- 操作系统后台自动将PageCache的数据SYNC同步到磁盘文件中
- 其他的follower到leader中同步数据

#### Kafka的读取过程

- 消费者通过Topic，分区，offset等信息来请求读取数据
- Kafka根据元数据信息来找到对应的副本节点
- 在节点上先读取PageCache，通过0拷贝机制读取PageChe（内存直接到网络）
- 如果PageCache中没有，根据offset找到segment，将segment的索引文件加载到内存中，根据索引信息找到数据

#### Kafka读写为什么快？

- 写：先写内存，顺序写磁盘

- 读：先读PageCache+零拷贝，基于Offset顺序消费+Segment+稀疏索引

#### Kafka索引类型，检索步骤

类型

- 全量索引：一条数据对应一条索引
- 稀疏索引：部分数据由索引

检索步骤：

- 根据offset计算出属于哪个Segment文件对
- 读取.index索引，找到最近的位置
- 从.log文件中读取到啊哟查找的数据

#### Kafka清理规则：

因为kafka讲求的是实时性，所以过期数据需要清理来释放内存

- delete
  - 基于时间清除
  - 基于文件大小清除
  - 基于offset清除
- Compact
  - 相同的key的数据，将老版本删除

#### Kafka数据积压（背压）是什么？怎么解决？

- 消费跟不上生产速度，导致处理延迟，产生数据积压
- 原因：
  - 消费者并发能力太低
  - 消费者处理失败
  - 网络故障
- 解决：
  - 提高消费者组中消费者的并行度
  - 如果是处理失败，找到报错原因
  - 查看监控
  - 都解决不了，限制生产

