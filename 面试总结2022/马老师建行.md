#### Hive调优

Hive调优一般是解决数据处理效率问题，可以通过一些配置来加快运行速度

- fetch抓取机制，这种机制开启之后，sql能不走mr就不走mr，比如开启后全局查找，字段查找，limit查找，sql都不会走mr
- 开启推测执行机制，一个job底层有多个task执行，某些task执行慢，推测机制可以利用算法找出这些task，然后设置备份，两份一起执行，谁先执行完，谁作为最终的处理结果
- join优化，hive 如果在执行join时会有两阶段的join，map端join和reduce端的join，可以设置开启map join，然后给表设置阈值，指定不超过多少阈值可以走mapjoin
- 如果时大表join大表
  - 可以先对空key进行过滤
  - 如果某些key值过多，可以用加盐的方式  case when key = xxx then
- 数据倾斜优化，一般在group by key后会出现数据倾斜
  - 开启map端预聚合这个参数
  - 然后设置map端预聚合的条目数据
  - 如果有数据倾斜的时候进行负载均衡
    - 原理：碰到数据倾斜再开启一个MR程序，将倾斜的数据发送到各个reduce中，打散后进行局部聚合
    - 完成后再启动一个mapreduce程序，将上一步的聚合结果汇总起来再进行一次聚合

#### Flink调优

- 资源配置优化
  - 内存设置，jobmanager内存，taskmanager内存
  - 并行度设置，
    - source端并行度尽量和kafka topic分区数相等
    - transform端并行度如果作业过多可以往高一点配
    - sink端可以按照下游kafka topic分区数或者其他组件的分区数配置
- 反压处理
  - 利用web ui或者grafana等监控组件查看是否反压
  - 一般反压都是负载不均衡导致了数据倾斜
    - keyby之前，查看kafka topic中的分区数据量，如果是这个原因，需要用到shuffle，rebalance算子重新分配数据
    - 如果是keyby之后的窗口出现数据倾斜，可以用两阶段聚合的方式，第一阶段给key加盐进行聚合，完成后第二阶段去掉加盐，然后再聚合一次
- flink sql调优
  - 开启minibatch，微批处理，减少对state的访问，提高吞吐量
  - 开启localgloabl，可以将aggregate等聚合算子分为local+gloabl两阶段去处理，解决热点问题
  - 开启split distinct，localgolable对本地去重率并不高，split distinct可以将本地数据重新打散去重再聚合
  - case when换位filter，filter可以共享一个对象实例，减少对状态的访问

#### spark作业提交后如何找出有问题的代码

- 如果是程序出错，可以在yarn或者spark web ui 找到作业 id，找到报错信息
- 如果是程序没有错，可以在数仓分层中找出血缘关系，按照血缘关系找出程序中的dateframe，然后慢慢找出错误。

#### 如何建立二级索引

```sql
--全局索引，给表按照指定的字段创建一个索引
create index indexname on tablename(colname)
--覆盖索引，给表按照以后需要经常查询的字段创建一个索引
create index indexname on tablename(colname) include (colname2)
--本地索引，把索引写在每个region上的表的头部，会更改原表内容，速度最快
create local index indexname on tablename(col1,col2,col3....)
```

#### 如何在已有的二级索引前提下增加二级索引

- 这种情况下可以用覆盖索引，重新按照需求创建一张索引表，因为在pheonix中，覆盖索引原理就是另外创建一张索引表。
- 如果是要更改这张索引表，没见过类似场景，不太了解，如果这类场景很多，我建议使用clickhouse，会更加的灵活一点。

#### 如何快速的从hbase(pheonix)中导出数据

- sqoop import ，通过用jdbc驱动链接pheonix来导出hbase的数据
  - 只可以导出表
- pheonix提供一个海量数据导出的工具，jdbc pig loader
  - 可以导出表
  - 也可导出查询的东西

#### 项目细节的提问和深挖

#### 项目的体量