#### Flink的分布式架构有哪些？

- 主：JobManager
  - dispatcher：负责接收用户提供的作业，拉起新的jobmanager
  - resourcemanager：负责资源的管理
  - jobMaster：负责管理作业的执行
- 从：TaskManager
  - 负责数据的读写与计算
- Opeartor：从客户端接收到的程序会划分为多个opeartor，每个operator会划分为多个task
  - one to one模式：上游与下游分区数据处理后一一对应
  - Redistributing模式：上游数据聚合或者拆分后重新分配到下游
- Opeartor Chain执行链：在one to one模式且并行度相同德情况下，可以生成operator Chain执行链，这玩意可以减少线程的切换和缓冲的开销，减少延迟
- Task：Operator拆分的任务单位，一个task可以拆分为多个subtask
- slot：物理逻辑，task的执行位置，一个task对应一个slot
- Execution Graph物理执行图：
  - 首先根据程序生成一个程序原本的streamGraph
  - 然后将满足chain条件的subtask合并一个执行链生成jobgraph
  - 在jobgraph上加入并行度，形成executiongraph
  - 申请资源，将excutiongraph中subtask放在slot，任务开始执行

#### Flink和Spark Streaming的区别

- 时间处理，Spark Streaming只支持处理时间，Flink时间有三种：事件时间，处理时间，注入时间，还支持了watermark来处理滞后数据
- 容错机制：spark streaming可以checkpoint，可以保证数据不丢失，但无法保证不重复，Flink可以用两阶段提交来解决这个问题
- Spark Streaming本质上是微批，以批为核心，Flink本质上是以流为核心的。

#### Flink的运行模式有哪几种？

- local
- standalone
- yarn
- K8s

#### Flink on yarn的执行流程？

- 首先提交作业，把Jar包和配置文件提交到HDFS，同时任务提交到yarn的主节点ResourceManager，RM在NodeManager上启动容器，运行Appmaster
- AppMaster加载Flink的jar包和配置构建环境，启动JobManager
- JobManager启动后会为TaskManager生成一个新的配置文件，AppMaster会用这个配置文件向RM申请资源
- RM把资源分配给NM，NM会根据分配的资源启动多个Flink的TaskManager
- 启动完成后，TM会给JM发送心跳包，等待JM向它分配任务

#### Flink的四大基石

- 时间和窗口
  - 滚动窗口：每5s开一个窗，不会重复
    - 计数窗口
    - 时间窗口
  - 滑动窗口：每5s查看近10s的数据，会重复
    - 计数窗口
    - 时间窗口
  - 会话窗口
- 状态和检查点

#### Flink窗口API分为哪几类？

- keyedStream：先对窗口内的数据进行分组，然后进行计算
- 非keyedStream：不进行分组，直接对窗口内的所有数据进行计算

#### Flink常用的算子有哪些？

- 数据读取：fromElements，readtextfile，socketTextStream
- 转换：Map，FlatMap，Filter，KeyBy，Window，Split，shuffle，rebalence,global,forward

#### Flink的分区策略

- shuffle partitioner：均匀的给下游task分配数据
- broatcast partitioner：把一份流数据广播给所有的分区
- rebalence partitioner：用轮询的方式把每个数据分配分区
- Global partitioner：把所有数据发送到下游的一个实例中处理
- ForwardPartitioner：上游分区的datastream在下游新建一份，要求上游和下游并行度一样

#### Flink如何保证窗口数据的一致性语义？

出现原因：网络延迟或机器问题会导致数据晚来

解决：

- 首先水印机制（watermark），给窗口加一个延迟数据时间戳，让延迟数据即使是错过窗口时间，也能进入对应的窗口
- 如果水印时间还没有到达，可以使用ALLowed Lateness再加一个延迟时间
- 如果Allowed lateness时间还没到达，可以使用side output进行侧边流处理

#### Flink Time机制？

- 事件事件：数据产出的时间
- 摄入时间：数据进入flink的时间
- 处理时间：数据被处理的时间

#### Flink状态和检查点是干什么的？

- 状态：记录Flink任务的中间结果，把结果存在内存中
- 检查点：把状态持久化到外部文件系统中

#### Flink的状态CheckPoint的执行流程？Flink的容错机制？

- jobmanager创建checkpoint协调器
- 协调器向各个任务发送barrier
- 收到barrier后制作state快照并进行存储，存储完成后向协调器汇报，把Barrier发送给下游
- 重复上面的步骤，直到flink的job都完成
- 协调器收到所有任务执行OK的汇报结果，完成checkpoint

#### checkpoint 方法配置

- enableCheckpointing   状态持久化头与头之间的间隔

- checkpoinTimeout  状态持久化超时时间

- MaxConcurrentCheckpoints  状态持久化最大并行度

- MinPauseBetweenCheckpoints   两个checkpoint之间执行的时间间隔

#### 什么是Barrier对齐？

同一阶段的subtask必须所有都收到上游发送的barrier，才能继续进行下一阶段的checkpoint

如果不这样做，无法实现exectly once语义。

#### Flink的状态在后端存储有几种方式？

- 内存：默认情况下会把checkpoint的状态放在jobmanager的内存里
- 分布式文件系统：一般生产中会把状态存储在分布式文件系统中
- RockesDB：全量持久化，增量持久化

#### Flink的状态checkpoint存储后，需要恢复，如何恢复？

- 手动重启程序：在flink ui提交作业
- 通过配置Flink-conf，让程序自动重启

#### 什么是State TTL，state的分类有哪些？什么是Savepoint

- ttl：状态的存活时间

- state分类：

  - keyed state

  - operator state

- SavePoint：手动的进行Snapshot

#### Flink一致性语义怎么实现？

flink内部已经靠checkpoint实现了内部的exactly-onece，如果要实现端对端，要求外部系统也需要支持精准一次的语义

1：source：支持重设数据的读取位置，比如offset，当kafka消费者充当source端的时候

2：transformation：checkpoint检查点机制

3：sink，要么支持幂等性写入，要么事务写入

- 幂等性写入：比如kafka生产者，在传输ack的过程中会有ack丢失的情况，数据会重新传输，导致数据重复，如果给数据加一个id，实现幂等，就能避免数据重复
- 事务写入：
  - WAL：把结果数据先当成状态保存，在收到checkpoint完成的通知时，一次性写入sink系统
  - 2PC：每一个checkpoint都会启动一个事务，每个事务的结果保存下来但先不提交，只是“预提交”，一旦所有的任务都完成，再进行一次提交

#### 什么是两阶段提交？

每一个checkpoint都会启动一个事务，每个事务的结果保存下来但先不提交，只是“预提交”，一旦所有的任务都完成，再进行一次提交

#### Flink反压？怎么解决？

上游数据发送太快，下游节点处理不过来。导致队列阻塞后，影响上游生产

解决：

- 首先通过flink web ui查看反压节点

#### Flink SQL原理是什么？

- 将SQL使用***\*Calcite\**** 转换为DateStream，提交到集群上运行

#### Flink sql怎么操作窗口？

- 滚动窗口GROUP BY TUMBLE
- 滑动窗口GROUP BY HOP

- 会话窗口GROUP BY Session
- 累加窗口GROUP BY Cumulate

#### Flink sql表元数据管理用的是什么？

Hivecatalog

#### Flink sql结果的三种模式？

- 表格
- 日志
- 数据库

#### Flink SQL支持哪几种join？

支持三种join方式

- 流与流的join
  - regular join
    - inner join
    - out join
    - full join
  - interval join
    - 计算两条流在一段时间区间内的join操作，用一条流去join另一条流前后一段时间内的数据
  - temporal join
    - 用于快照的join
- 流与维表的join
  - look up join
- 动态表字段的列转行
  - table function
    - udf函数，需要自定义实现
  - array expansion
    - 将array压平转为多行
    - 适用于一列转多行

Flink中的time有哪几种？

- event time ：事件的发生时间
- ingestion time ：数据进入flink时间
- Processing Time： 算子的本地系统时间

#### 多个流之间如何join？

- interval join 基于时间间隔join
- window cogroup联合分组



